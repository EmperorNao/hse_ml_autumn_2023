<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>4af9f6ce2eaa495b92ef442639f3b13e</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="машинное-обучение" class="cell markdown" id="KYY67hawSxmX">
<h1>Машинное обучение</h1>
<h2 id="домашнее-задание-1-knn--линейные-модели">Домашнее задание №1:
KNN + Линейные модели</h2>
</section>
<div class="cell markdown" id="VOzlZa9NSxmZ">
<p><strong>Срок сдачи:</strong> 10 октября 2023, 23:59</p>
<p><strong>Максимально баллов:</strong> 10</p>
<p><strong>Штраф за опоздание:</strong> по 2 балла за 24 часа задержки.
Через 5 дней домашнее задание сгорает.</p>
<p>При отправлении ДЗ указывайте фамилию в названии файла. Формат сдачи
будет указан чуть позже.</p>
<p>Используйте данный Ipython Notebook при оформлении домашнего
задания.</p>
</div>
<div class="cell markdown" id="7ecd3P33SxmZ">
<p><strong>Штрафные баллы:</strong></p>
<ol>
<li>Отсутствие фамилии в имени скрипта (скрипт должен называться по
аналогии со stroykova_hw1.ipynb) -1 баллов</li>
<li>Все строчки должны быть выполнены. Нужно, чтобы output команды можно
было увидеть уже в git'е. В противном случае -1 баллов</li>
</ol>
<p>При оформлении ДЗ нужно пользоваться данным файлом в качестве
шаблона. Не нужно удалять и видоизменять написанный код и текст, если
явно не указана такая возможность.</p>
</div>
<section id="knn-5-баллов" class="cell markdown" id="e1DOBvR3SxmZ">
<h2>KNN (5 баллов)</h2>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="E5hDM7RTSxmZ" data-outputId="a1635056-f618-4416-d91a-87f5ba580dd9">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install seaborn</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install numpy<span class="op">==</span><span class="fl">1.22.4</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)
Requirement already satisfied: numpy!=1.24.0,&gt;=1.17 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.22.4)
Requirement already satisfied: pandas&gt;=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)
Requirement already satisfied: matplotlib!=3.6.1,&gt;=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)
Requirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (1.1.0)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (0.11.0)
Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (4.42.1)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (1.4.5)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (23.1)
Requirement already satisfied: pillow&gt;=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (9.4.0)
Requirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (3.1.1)
Requirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas&gt;=0.25-&gt;seaborn) (2023.3.post1)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (1.16.0)
Requirement already satisfied: numpy==1.22.4 in /usr/local/lib/python3.10/dist-packages (1.22.4)
</code></pre>
</div>
</div>
<div class="cell code" id="R-JfG6NySxmb">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> functools <span class="im">import</span> partial</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> datasets</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.base <span class="im">import</span> BaseEstimator</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_openml <span class="im">as</span> fetch_mldata, fetch_20newsgroups</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span></code></pre></div>
</div>
<section id="задание-1-1-балл" class="cell markdown" id="wjZOQ0WWSxmb">
<h5>Задание 1 (1 балл)</h5>
<p>Реализовать KNN в классе MyKNeighborsClassifier (обязательное
условие: точность не ниже sklearn реализации) Разберитесь
самостоятельно, какая мера расстояния используется в
KNeighborsClassifier дефолтно и реализуйте свой алгоритм именно с этой
мерой. Для подсчета расстояний можно использовать функции <a
href="https://docs.scipy.org/doc/scipy/reference/spatial.distance.html">отсюда</a></p>
</section>
<div class="cell code" id="n0ECA-ZFSxmb">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KDTree</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.spatial.distance <span class="im">import</span> cdist</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyKNeighborsClassifier(BaseEstimator):</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_neighbors, metric<span class="op">=</span><span class="st">&#39;minkowski&#39;</span>, algorithm<span class="op">=</span><span class="st">&#39;brute&#39;</span>):</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X <span class="op">=</span> <span class="va">None</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> <span class="va">None</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tree <span class="op">=</span> <span class="va">None</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.metric <span class="op">=</span> metric</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_neighbors <span class="op">=</span> n_neighbors</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.algorithm <span class="op">=</span> algorithm</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y):</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X <span class="op">=</span> X</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> y</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.algorithm <span class="op">==</span> <span class="st">&#39;kd_tree&#39;</span>:</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.tree <span class="op">=</span> KDTree(<span class="va">self</span>.X, leaf_size<span class="op">=</span><span class="dv">2</span>, metric<span class="op">=</span><span class="va">self</span>.metric)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.algorithm <span class="op">==</span> <span class="st">&#39;brute&#39;</span>:</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>            distances <span class="op">=</span> cdist(X, <span class="va">self</span>.X, metric<span class="op">=</span><span class="va">self</span>.metric)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>            sorted_indeces <span class="op">=</span> distances.argsort(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>            _, sorted_indeces <span class="op">=</span> <span class="va">self</span>.tree.query(X, k<span class="op">=</span><span class="va">self</span>.n_neighbors)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> <span class="va">self</span>.y[sorted_indeces][:, :<span class="bu">min</span>(<span class="va">self</span>.y.shape[<span class="dv">0</span>], <span class="va">self</span>.n_neighbors)]</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># unfortunately np.unique doesn&#39;t work properly for 2dim arrays</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>        combined_predictions <span class="op">=</span> []</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> prediction <span class="kw">in</span> predictions:</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>                classes, counts <span class="op">=</span> np.unique(prediction, return_counts<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>                combined_predictions.append(classes[counts.argmax()])</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.array(combined_predictions)</span></code></pre></div>
</div>
<div class="cell markdown" id="86EU-cYTSxmc">
<p><strong>IRIS</strong></p>
<p>В библиотеке scikit-learn есть несколько датасетов из коробки. Один
из них <a
href="https://ru.wikipedia.org/wiki/%D0%98%D1%80%D0%B8%D1%81%D1%8B_%D0%A4%D0%B8%D1%88%D0%B5%D1%80%D0%B0">Ирисы
Фишера</a></p>
</div>
<div class="cell code" id="k9hDy9_gSxmc">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>iris <span class="op">=</span> datasets.load_iris()</span></code></pre></div>
</div>
<div class="cell code" id="nn1Xam6NSxmc">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(iris.data, iris.target, test_size<span class="op">=</span><span class="fl">0.1</span>, stratify<span class="op">=</span>iris.target)</span></code></pre></div>
</div>
<div class="cell code" id="Af_HfJKbSxmc">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">2</span>, algorithm<span class="op">=</span><span class="st">&#39;brute&#39;</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>my_clf <span class="op">=</span> MyKNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">2</span>, algorithm<span class="op">=</span><span class="st">&#39;brute&#39;</span>)</span></code></pre></div>
</div>
<div class="cell code" id="TgiKVqngSxmc">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>clf.fit(X_train, y_train)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>my_clf.fit(X_train, y_train)</span></code></pre></div>
</div>
<div class="cell code" id="nIio38eBSxmd">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>sklearn_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>my_clf_pred <span class="op">=</span> my_clf.predict(X_test)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">abs</span>( accuracy_score(y_test, my_clf_pred) <span class="op">-</span>  accuracy_score(y_test, sklearn_pred ) )<span class="op">&lt;</span><span class="fl">0.005</span>, <span class="st">&quot;Score must be simillar&quot;</span></span></code></pre></div>
</div>
<div class="cell markdown" id="0cJZzNhYSxmd">
<p><strong>Задание 2 (0.5 балла)</strong></p>
<p>Давайте попробуем добиться скорости работы на fit, predict сравнимой
со sklearn для iris. Допускается замедление не более чем в 2 раза. Для
этого используем numpy.</p>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="MfcaOs2FSxmd" data-outputId="f08278d2-b71e-462a-804d-3b1dfd3665b6">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit clf.fit(X_train, y_train)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>645 µs ± 127 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="jTLBc9QjSxmd" data-outputId="0cd2b1aa-35ea-4e90-d164-88f419f40bc1">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit my_clf.fit(X_train, y_train)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>195 µs ± 26.7 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="sHcDB1LaSxmd" data-outputId="581f573c-ee8d-4d20-b8e2-0456664737fa">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit clf.predict(X_test)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>2.06 ms ± 305 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="Rff-3Wg9Sxme" data-outputId="be59b8d8-ddee-49c2-8695-2fb263c6286a">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit my_clf.predict(X_test)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>589 µs ± 138 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
</code></pre>
</div>
</div>
<section id="задание-3-1-балл" class="cell markdown" id="ReTeb85ISxme">
<h6>Задание 3 (1 балл)</h6>
<p>Добавьте algorithm='kd_tree' в реализацию KNN (использовать KDTree из
sklearn.neighbors). Необходимо добиться скорости работы на fit, predict
сравнимой со sklearn для iris. Допускается замедление не более чем в 2
раза. Для этого используем numpy. Точность не должна уступать значению
KNN из sklearn.</p>
</section>
<div class="cell code" id="PljB_81bSxme">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">2</span>, algorithm<span class="op">=</span><span class="st">&#39;kd_tree&#39;</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>my_clf <span class="op">=</span> MyKNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">2</span>, algorithm<span class="op">=</span><span class="st">&#39;kd_tree&#39;</span>)</span></code></pre></div>
</div>
<div class="cell code" id="Xj4YlNkGSxme">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(iris.data, iris.target, test_size<span class="op">=</span><span class="fl">0.1</span>, stratify<span class="op">=</span>iris.target)</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="lN5XXwKsSxme" data-outputId="2f2d191d-06bd-43cc-a764-60316edbeed3">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit clf.fit(X_train, y_train)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>727 µs ± 258 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="6G5YCBw8Sxme" data-outputId="7c8d74bd-39f6-41c3-aa33-1c7031c28b7c">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit my_clf.fit(X_train, y_train)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>248 µs ± 40.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="jyy24PjzSxmf" data-outputId="7f004463-be3c-4594-9f18-00882134588e">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit clf.predict(X_test)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>2.07 ms ± 216 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="nhgS02otSxmf" data-outputId="00faadd0-e389-4a8b-b250-2f06ea308811">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit my_clf.predict(X_test)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>445 µs ± 22 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
</code></pre>
</div>
</div>
<div class="cell code" id="uVa7hoQ5Sxmf">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>sklearn_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>my_clf_pred <span class="op">=</span> my_clf.predict(X_test)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">abs</span>( accuracy_score(y_test, my_clf_pred) <span class="op">-</span>  accuracy_score(y_test, sklearn_pred ) )<span class="op">&lt;</span><span class="fl">0.005</span>, <span class="st">&quot;Score must be simillar&quot;</span></span></code></pre></div>
</div>
<div class="cell markdown" id="MrMt7xRnSxmf">
<p><strong>Задание 4 (2.5 балла)</strong></p>
<p>Рассмотрим новый датасет 20 newsgroups</p>
</div>
<div class="cell code" id="Rg59wsl7Sxmf">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>newsgroups <span class="op">=</span> fetch_20newsgroups(subset<span class="op">=</span><span class="st">&#39;train&#39;</span>,remove<span class="op">=</span>(<span class="st">&#39;headers&#39;</span>,<span class="st">&#39;footers&#39;</span>, <span class="st">&#39;quotes&#39;</span>))</span></code></pre></div>
</div>
<div class="cell code" id="apS-8iotSxmf">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> newsgroups[<span class="st">&#39;data&#39;</span>]</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> newsgroups[<span class="st">&#39;target&#39;</span>]</span></code></pre></div>
</div>
<div class="cell markdown" id="vzai_d0jSxmf">
<p>Преобразуйте текстовые данные из data с помощью <a
href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">CountVectorizer</a>.
Словарь можно ограничить по частотности.</p>
</div>
<div class="cell code" id="wSdGwiL5Sxmf">
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer, TfidfVectorizer</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>vectorizer <span class="op">=</span> CountVectorizer(min_df<span class="op">=</span><span class="dv">50</span>, max_df<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>vectorizer.fit(X_train)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>X_train_transformed <span class="op">=</span> vectorizer.transform(X_train)</span></code></pre></div>
</div>
<div class="cell markdown" id="KMiPN_gPSxmg">
<p><em>Так мы получили векторное представление наших текстов. Значит
можно приступать к задаче обучения модели</em></p>
</div>
<div class="cell markdown" id="3r6eSxIqSxmg">
<p>Реализуйте разбиение выборки для кросс-валидации на 3 фолдах.
Разрешено использовать sklearn.cross_validation</p>
</div>
<div class="cell code" id="czOMkWkVSxmg">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_validate</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="L8A0TOaDSxmg" data-outputId="ae576ec8-22c9-44b1-d011-8478f87ca51e">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>my_clf <span class="op">=</span> MyKNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">2</span>, algorithm<span class="op">=</span><span class="st">&#39;kd_tree&#39;</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>cross_validate(my_clf, X_train_transformed[:<span class="dv">1000</span>, :].toarray(), y_train[:<span class="dv">1000</span>], cv<span class="op">=</span><span class="dv">3</span>, scoring<span class="op">=</span>(<span class="st">&#39;accuracy&#39;</span>))</span></code></pre></div>
<div class="output execute_result" data-execution_count="153">
<pre><code>{&#39;fit_time&#39;: array([0.30100226, 0.51216316, 0.28369641]),
 &#39;score_time&#39;: array([7.73899221, 7.24414706, 8.24708581]),
 &#39;test_score&#39;: array([0.08982036, 0.11711712, 0.10510511])}</code></pre>
</div>
</div>
<div class="cell markdown" id="oD3pl_WtSxmg">
<p>Напишите метод, позволяющий найти оптимальное количество ближайших
соседей(дающее максимальную точность в среднем на валидации на 3
фолдах). Постройте график зависимости средней точности от количества
соседей. Можно рассмотреть число соседей от 1 до 10.</p>
</div>
<div class="cell code" data-collapsed="true" id="lDLP8d_ISxmg">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_average_test_accuracy(X, y, vectorizer, cls, n_neighbors, metric):</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    transformed_X <span class="op">=</span> vectorizer.fit_transform(X)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    classifier <span class="op">=</span> cls(metric<span class="op">=</span>metric, n_neighbors<span class="op">=</span>n_neighbors)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    cv_dict <span class="op">=</span> cross_validate(classifier, transformed_X.toarray(), y, cv<span class="op">=</span><span class="dv">3</span>, scoring<span class="op">=</span>(<span class="st">&#39;accuracy&#39;</span>))</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    test_acc <span class="op">=</span> cv_dict[<span class="st">&#39;test_score&#39;</span>]</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">sum</span>(test_acc) <span class="op">/</span> <span class="bu">len</span>(test_acc)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_models_history(X, y):</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    grid <span class="op">=</span> {</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;n_neighbors&#39;</span>: <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>)),</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;metrics&#39;</span>: [<span class="st">&#39;minkowski&#39;</span>, <span class="st">&#39;cosine&#39;</span>],</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;vectorizers&#39;</span>: [<span class="st">&#39;count&#39;</span>, <span class="st">&#39;tf-idf&#39;</span>]</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>    vectorizers_map <span class="op">=</span> {</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;count&#39;</span>: CountVectorizer,</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;tf-idf&#39;</span>: TfidfVectorizer</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> {}</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> vectorizer <span class="kw">in</span> grid[<span class="st">&#39;vectorizers&#39;</span>]:</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>        history[vectorizer] <span class="op">=</span> {}</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> metric <span class="kw">in</span> grid[<span class="st">&#39;metrics&#39;</span>]:</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>            history[vectorizer][metric] <span class="op">=</span> {}</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> n_neigbors <span class="kw">in</span> grid[<span class="st">&#39;n_neighbors&#39;</span>]:</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>                vc <span class="op">=</span> vectorizers_map[vectorizer](min_df<span class="op">=</span><span class="dv">50</span>, max_df<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>                history[vectorizer][metric][n_neigbors] <span class="op">=</span> get_average_test_accuracy(X, y, vc, MyKNeighborsClassifier, n_neigbors, metric)</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> history</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_history(history, name<span class="op">=</span><span class="st">&quot;accuracy&quot;</span>):</span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(<span class="bu">list</span>(history.keys())[<span class="dv">0</span>], <span class="bu">str</span>):</span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> key, value <span class="kw">in</span> history.items():</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>            plot_history(value, name <span class="op">+</span> <span class="st">&quot;_&quot;</span> <span class="op">+</span> key)</span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span></span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))</span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="bu">list</span>(history.keys())</span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> <span class="bu">list</span>(history.values())</span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a>    max_idx <span class="op">=</span> np.argmax(y)</span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a>    plt.plot(x, y)</span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a>    plt.plot(x[max_idx], y[max_idx], <span class="st">&#39;bo&#39;</span>, label<span class="op">=</span><span class="st">&quot;(n </span><span class="sc">%i</span><span class="st">, acc </span><span class="sc">%f</span><span class="st">)&quot;</span> <span class="op">%</span> (x[max_idx], y[max_idx]))</span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">&quot;Test cv=3 </span><span class="sc">%s</span><span class="st">&quot;</span> <span class="op">%</span> name)</span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a>    fig.show()</span></code></pre></div>
</div>
<div class="cell code" id="Nc5G1cn5ahLL">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> get_models_history(X_train, y_train)</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="fI3EMLbya_W6" data-outputId="5d68244a-6790-466c-9f9f-9933a8cd48f4">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>plot_history(history)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_660fc6be0f2444d2af7376729dacc244/1291e6277201344330a4109b402b185291ece9e8.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_660fc6be0f2444d2af7376729dacc244/43f310760bc9c13465258659dff56271f53af6e4.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_660fc6be0f2444d2af7376729dacc244/49868282bb524ad0b170e4db0f8ebb6b2f1930f5.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_660fc6be0f2444d2af7376729dacc244/5c551be7b46c2a28aec13531895c951810091825.png" /></p>
</div>
</div>
<div class="cell markdown" id="myf10F3GSxmq">
<p>Как изменится качество на валидации, если:</p>
<ol>
<li>Используется косинусная метрика вместо евклидовой.</li>
<li>К текстам применяется TfIdf векторизацию(
sklearn.feature_extraction.text.TfidfVectorizer)</li>
</ol>
<p>Сравните модели, выберите лучшую.</p>
</div>
<div class="cell markdown" id="9lIP_ZzWSxmq">
<p>Загрузим теперь test  часть нашей выборки и преобразуем её аналогично
с train частью. Не забудьте, что наборы слов в train и test части могут
отличаться.</p>
</div>
<div class="cell code" data-collapsed="true" id="lfEj2R5aSxmq">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>newsgroups <span class="op">=</span> fetch_20newsgroups(subset<span class="op">=</span><span class="st">&#39;test&#39;</span>,remove<span class="op">=</span>[<span class="st">&#39;headers&#39;</span>,<span class="st">&#39;footers&#39;</span>, <span class="st">&#39;quotes&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" id="Zg1pdZRgheki">
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> newsgroups[<span class="st">&#39;data&#39;</span>]</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> newsgroups[<span class="st">&#39;target&#39;</span>]</span></code></pre></div>
</div>
<div class="cell markdown" id="WHSKW1IASxmr">
<p>Оценим точность вашей лучшей модели на test части датасета.
Отличается ли оно от кросс-валидации? Попробуйте сделать выводы, почему
отличается качество.</p>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="d4i-DUiBSxmr" data-outputId="65f9f007-c77f-453a-8a06-535b8b5d4133">
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>best_model <span class="op">=</span> MyKNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">9</span>, metric<span class="op">=</span><span class="st">&#39;cosine&#39;</span>, algorithm<span class="op">=</span><span class="st">&#39;brute&#39;</span>)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>vectorizer <span class="op">=</span> TfidfVectorizer(min_df<span class="op">=</span><span class="dv">50</span>, max_df<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>transformed_X_train, transformed_y_train <span class="op">=</span> vectorizer.fit_transform(X_train), y_train</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>best_model.fit(transformed_X_train.toarray(), transformed_y_train)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>transformed_X_test <span class="op">=</span> vectorizer.transform(X_test)</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> best_model.predict(transformed_X_test.toarray())</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Качество значимо лучше, т.к учимся на всех данных, а не на двух фолдах</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(accuracy_score(y_test, y_pred))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>0.6383430695698353
</code></pre>
</div>
</div>
<section id="линейные-модели-5-баллов" class="cell markdown"
data-collapsed="true" id="lC0rJLINSxmr">
<h1>Линейные модели (5 баллов)</h1>
</section>
<div class="cell code" id="2VgMkqHRSxmr">
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">&#39;ggplot&#39;</span>)</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">&#39;figure.figsize&#39;</span>] <span class="op">=</span> (<span class="dv">12</span>,<span class="dv">5</span>)</span></code></pre></div>
</div>
<div class="cell markdown" id="lvYHDzwJSxmr">
<p>В этом задании мы будем реализовать линейные модели. Необходимо
реализовать линейную и логистическую регрессии с L2 регуляризацией</p>
<h3 id="теоретическое-введение">Теоретическое введение</h3>
<p>Линейная регрессия решает задачу регрессии и оптимизирует функцию
потерь MSE</p>
<p><span class="math display">$$L(w) =  \frac{1}{N}\left[\sum_i (y_i -
a_i) ^ 2 \right], $$</span> где <span
class="math inline"><em>y</em><sub><em>i</em></sub></span> <span
class="math inline">−</span> целевая функция, <span
class="math inline"><em>a</em><sub><em>i</em></sub> = <em>a</em>(<em>x</em><sub><em>i</em></sub>) = ⟨ <em>x</em><sub><em>i</em></sub>, <em>w</em>⟩,</span>
<span class="math inline">−</span> предсказание алгоритма на объекте
<span class="math inline"><em>x</em><sub><em>i</em></sub></span>, <span
class="math inline"><em>w</em></span> <span class="math inline">−</span>
вектор весов (размерности <span class="math inline"><em>D</em></span>),
<span class="math inline"><em>x</em><sub><em>i</em></sub></span> <span
class="math inline">−</span> вектор признаков (такой же размерности
<span class="math inline"><em>D</em></span>).</p>
<p>Не забываем, что здесь и далее мы считаем, что в <span
class="math inline"><em>x</em><sub><em>i</em></sub></span> есть
тождественный вектор единиц, ему соответствует вес <span
class="math inline"><em>w</em><sub>0</sub></span>.</p>
<p>Логистическая регрессия является линейным классификатором, который
оптимизирует так называемый функционал log loss:</p>
<p><span class="math display">$$L(w) = - \frac{1}{N}\left[\sum_i y_i
\log a_i + ( 1 - y_i) \log (1 - a_i) \right],$$</span> где <span
class="math inline"><em>y</em><sub><em>i</em></sub> ∈ {0, 1}</span>
<span class="math inline">−</span> метка класса, <span
class="math inline"><em>a</em><sub><em>i</em></sub></span> <span
class="math inline">−</span> предсказание алгоритма на объекте <span
class="math inline"><em>x</em><sub><em>i</em></sub></span>. Модель
пытается предсказать апостериорую вероятность объекта принадлежать к
классу "1": <span
class="math display"><em>p</em>(<em>y</em><sub><em>i</em></sub>=1|<em>x</em><sub><em>i</em></sub>) = <em>a</em>(<em>x</em><sub><em>i</em></sub>) = <em>σ</em>(⟨ <em>x</em><sub><em>i</em></sub>,<em>w</em>⟩),</span>
<span class="math inline"><em>w</em></span> <span
class="math inline">−</span> вектор весов (размерности <span
class="math inline"><em>D</em></span>), <span
class="math inline"><em>x</em><sub><em>i</em></sub></span> <span
class="math inline">−</span> вектор признаков (такой же размерности
<span class="math inline"><em>D</em></span>).</p>
<p>Функция <span class="math inline"><em>σ</em>(<em>x</em>)</span> <span
class="math inline">−</span> нелинейная функция, пероводящее скалярное
произведение объекта на веса в число <span
class="math inline"> ∈ (0,1)</span> (мы же моделируем вероятность
все-таки!)</p>
<p><span class="math display">$$\sigma(x) = \frac{1}{1 +
\exp(-x)}$$</span></p>
<p>Если внимательно посмотреть на функцию потерь, то можно заметить, что
в зависимости от правильного ответа алгоритм штрафуется или функцией
<span class="math inline"> − log <em>a</em><sub><em>i</em></sub></span>,
или функцией <span
class="math inline"> − log (1−<em>a</em><sub><em>i</em></sub>)</span>.</p>
<p>Часто для решения проблем, которые так или иначе связаны с проблемой
переобучения, в функционал качества добавляют слагаемое, которое
называют <strong><em>регуляризацией</em></strong>. Итоговый функционал
для линейной регрессии тогда принимает вид:</p>
<p><span class="math display">$$L(w) =  \frac{1}{N}\left[\sum_i (y_i -
a_i) ^ 2 \right] + \frac{1}{C}R(w) $$</span></p>
<p>Для логистической: <span class="math display">$$L(w) = -
\frac{1}{N}\left[\sum_i y_i \log a_i + ( 1 - y_i) \log (1 - a_i) \right]
+  \frac{1}{C}R(w)$$</span></p>
<p>Самое понятие регуляризации введено основателем ВМК академиком
Тихоновым <a
href="https://ru.wikipedia.org/wiki/Метод_регуляризации_Тихонова"
class="uri">https://ru.wikipedia.org/wiki/Метод_регуляризации_Тихонова</a></p>
<p>Идейно методика регуляризации заключается в следующем <span
class="math inline">−</span> мы рассматриваем некорректно поставленную
задачу (что это такое можно найти в интернете), для того чтобы сузить
набор различных вариантов (лучшие из которых будут являться
переобучением ) мы вводим дополнительные ограничения на множество
искомых решений. На лекции Вы уже рассмотрели два варианта
регуляризации.</p>
<p><span class="math inline"><em>L</em>1</span> регуляризация: <span
class="math display">$$R(w) = \sum_{j=1}^{D}|w_j|$$</span> <span
class="math inline"><em>L</em>2</span> регуляризация: <span
class="math display">$$R(w) =  \sum_{j=1}^{D}w_j^2$$</span></p>
<p>С их помощью мы ограничиваем модель в возможности выбора каких угодно
весов минимизирующих наш лосс, модель уже не сможет подстроиться под
данные как ей угодно.</p>
<p>Вам нужно добавить соотвествущую Вашему варианту <span
class="math inline"><em>L</em>2</span> регуляризацию.</p>
<p>И так, мы поняли, какую функцию ошибки будем минимизировать,
разобрались, как получить предсказания по объекту и обученным весам.
Осталось разобраться, как получить оптимальные веса. Для этого нужно
выбрать какой-то метод оптимизации.</p>
<p>Градиентный спуск является самым популярным алгоритмом обучения
линейных моделей. В этом задании Вам предложат реализовать
стохастический градиентный спуск или мини-батч градиентный спуск
(мини-батч на русский язык довольно сложно перевести, многие переводят
это как "пакетный", но мне не кажется этот перевод удачным). Далее нам
потребуется определение <strong>эпохи</strong>. Эпохой в SGD и MB-GD
называется один проход по <strong>всем</strong> объектам в обучающей
выборки.</p>
<ul>
<li>В SGD градиент расчитывается по одному случайному объекту. Сам
алгоритм выглядит примерно так: 1) Перемешать выборку 2) Посчитать
градиент функции потерь на одном объекте (далее один объект тоже будем
называть батчем) 3) Сделать шаг спуска 4) Повторять 2) и 3) пока не
пройдет максимальное число эпох.</li>
<li>В Mini Batch SGD - по подвыборке объектов. Сам алгоритм выглядит
примерно так:: 1) Перемешать выборку, выбрать размер мини-батча (от 1 до
размера выборки) 2) Почитать градиент функции потерь по мини-батчу (не
забыть поделить на число объектов в мини-батче) 3) Сделать шаг спуска 4)
Повторять 2) и 3) пока не пройдет максимальное число эпох.</li>
<li>Для отладки алгоритма реализуйте возможность вывода средней ошибки
на обучении модели по объектам (мини-батчам). После шага градиентного
спуска посчитайте значение ошибки на объекте (или мини-батче), а затем
усредните, например, по ста шагам. Если обучение проходит корректно, то
мы должны увидеть, что каждые 100 шагов функция потерь уменьшается.</li>
<li>Правило останова - максимальное количество эпох</li>
</ul>
</div>
<div class="cell markdown" id="ImKwDS-fSxmr">
<h2 id="зачем-нужны-батчи">Зачем нужны батчи?</h2>
<p>Как Вы могли заметить из теоретического введения, что в случае SGD,
что в случа mini-batch GD, на каждой итерации обновление весов
происходит только по небольшой части данных (1 пример в случае SGD,
batch примеров в случае mini-batch). То есть для каждой итерации нам ***
не нужна вся выборка***. Мы можем просто итерироваться по выборке, беря
батч нужного размера (далее 1 объект тоже будем называть батчом).</p>
<p>Легко заметить, что в этом случае нам не нужно загружать все данные в
оперативную память, достаточно просто считать батч с диска, обновить
веса, считать диска другой батч и так далее. В целях упрощения домашней
работы, прямо с диска мы считывать не будем, будем работать с обычными
numpy array.</p>
<h2 id="немножко-про-генераторы-в-python">Немножко про генераторы в
Python</h2>
<p>Идея считывания данных кусками удачно ложится на так называемые
<strong><em>генераторы</em></strong> из языка Python. В данной работе
Вам предлагается не только разобраться с логистической регрессией, но и
познакомиться с таким важным элементом языка. При желании Вы можете
убрать весь код, связанный с генераторами, и реализовать логистическую
регрессию и без них, <strong><em>штрафоваться это никак не
будет</em></strong>. Главное, чтобы сама модель была реализована
правильно, и все пункты были выполнены.</p>
<p>Подробнее можно почитать вот тут <a
href="https://anandology.com/python-practice-book/iterators.html"
class="uri">https://anandology.com/python-practice-book/iterators.html</a></p>
<p>К генератору стоит относиться просто как к функции, которая порождает
не один объект, а целую последовательность объектов. Новое значение из
последовательности генерируется с помощью ключевого слова
<strong><em>yield</em></strong>.</p>
<p>Концепция крайне удобная для обучения моделей <span
class="math inline">−</span> у Вас есть некий источник данных, который
Вам выдает их кусками, и Вам совершенно все равно откуда он их берет.
Под ним может скрывать как массив в оперативной памяти, как файл на
жестком диске, так и SQL база данных. Вы сами данные никуда не
сохраняете, оперативную память экономите.</p>
<p>Если Вам понравилась идея с генераторами, то Вы можете реализовать
свой, используя прототип batch_generator. В нем Вам нужно выдавать батчи
признаков и ответов для каждой новой итерации спуска. Если не
понравилась идея, то можете реализовывать SGD или mini-batch GD без
генераторов.</p>
</div>
<div class="cell code" id="h67LHaWkSxms">
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> batch_generator(X, y, shuffle<span class="op">=</span><span class="va">True</span>, batch_size<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Гератор новых батчей для обучения</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="co">    X          - матрица объекты-признаки</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="co">    y_batch    - вектор ответов</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="co">    shuffle    - нужно ли случайно перемешивать выборку</span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="co">    batch_size - размер батча ( 1 это SGD, &gt; 1 mini-batch GD)</span></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Генерирует подвыборку для итерации спуска (X_batch, y_batch)</span></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>    indexes <span class="op">=</span> np.arange(X.shape[<span class="dv">0</span>])</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> shuffle:</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>        indexes <span class="op">=</span> np.random.permutation(indexes)</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We are do not taking last batch if it&#39;s length less then batch_size</span></span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># because it can be too much noisy</span></span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_start <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(indexes) <span class="op">//</span> batch_size, batch_size):</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> X[batch_start: batch_start <span class="op">+</span> batch_size], y[batch_start: batch_start <span class="op">+</span> batch_size]</span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_batch_generator_wrapper(batch_size):</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> partial(batch_generator, batch_size<span class="op">=</span>batch_size)</span></code></pre></div>
</div>
<div class="cell code" id="4gOiCUSlSxms">
<div class="sourceCode" id="cb44"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Теперь можно сделать генератор по данным ()</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="co"># my_batch_generator = batch_generator(X, y, shuffle=True, batch_size=1)</span></span></code></pre></div>
</div>
<div class="cell code" id="lONwoz9YSxms">
<div class="sourceCode" id="cb45"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co">#%%pycodestyle</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(x):</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Вычисляем значение сигмоида.</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="co">    X - выход линейной модели</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>    sigm_value_x <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>x))</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sigm_value_x</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.base <span class="im">import</span> BaseEstimator, ClassifierMixin</span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MySGDClassifier(BaseEstimator, ClassifierMixin):</span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, batch_generator, C<span class="op">=</span><span class="dv">1</span>, alpha<span class="op">=</span><span class="fl">0.01</span>, max_epoch<span class="op">=</span><span class="dv">10</span>, model_type<span class="op">=</span><span class="st">&#39;lin_reg&#39;</span>):</span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a><span class="co">        batch_generator -- функция генератор, которой будем создавать батчи</span></span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a><span class="co">        C - коэф. регуляризации</span></span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a><span class="co">        alpha - скорость спуска</span></span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a><span class="co">        max_epoch - максимальное количество эпох</span></span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a><span class="co">        model_type - тим модели, lin_reg или log_reg</span></span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb45-25"><a href="#cb45-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-26"><a href="#cb45-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> model_type <span class="kw">in</span> [<span class="st">&#39;lin_reg&#39;</span>, <span class="st">&#39;log_reg&#39;</span>]</span>
<span id="cb45-27"><a href="#cb45-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.C <span class="op">=</span> C</span>
<span id="cb45-28"><a href="#cb45-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.eps <span class="op">=</span> <span class="fl">1e-6</span></span>
<span id="cb45-29"><a href="#cb45-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alpha <span class="op">=</span> alpha</span>
<span id="cb45-30"><a href="#cb45-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.max_epoch <span class="op">=</span> max_epoch</span>
<span id="cb45-31"><a href="#cb45-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_generator <span class="op">=</span> batch_generator</span>
<span id="cb45-32"><a href="#cb45-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.errors_log <span class="op">=</span> {<span class="st">&#39;iter&#39;</span> : [], <span class="st">&#39;loss&#39;</span> : []}</span>
<span id="cb45-33"><a href="#cb45-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model_type <span class="op">=</span> model_type</span>
<span id="cb45-34"><a href="#cb45-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-35"><a href="#cb45-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> calc_loss(<span class="va">self</span>, X_batch, y_batch):</span>
<span id="cb45-36"><a href="#cb45-36" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb45-37"><a href="#cb45-37" aria-hidden="true" tabindex="-1"></a><span class="co">        Считаем функцию потерь по батчу</span></span>
<span id="cb45-38"><a href="#cb45-38" aria-hidden="true" tabindex="-1"></a><span class="co">        X_batch - матрица объекты-признаки по батчу</span></span>
<span id="cb45-39"><a href="#cb45-39" aria-hidden="true" tabindex="-1"></a><span class="co">        y_batch - вектор ответов по батчу</span></span>
<span id="cb45-40"><a href="#cb45-40" aria-hidden="true" tabindex="-1"></a><span class="co">        Не забудте тип модели (линейная или логистическая регрессия)!</span></span>
<span id="cb45-41"><a href="#cb45-41" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb45-42"><a href="#cb45-42" aria-hidden="true" tabindex="-1"></a>        n_samples <span class="op">=</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb45-43"><a href="#cb45-43" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.calculate_model_output(X_batch)</span>
<span id="cb45-44"><a href="#cb45-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-45"><a href="#cb45-45" aria-hidden="true" tabindex="-1"></a>        reg_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb45-46"><a href="#cb45-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.C <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb45-47"><a href="#cb45-47" aria-hidden="true" tabindex="-1"></a>            reg_loss <span class="op">=</span> <span class="fl">1.</span><span class="op">/</span><span class="va">self</span>.C <span class="op">*</span> np.<span class="bu">sum</span>(<span class="va">self</span>.weights[<span class="dv">1</span>:] <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb45-48"><a href="#cb45-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-49"><a href="#cb45-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.model_type <span class="op">==</span> <span class="st">&#39;lin_reg&#39;</span>:</span>
<span id="cb45-50"><a href="#cb45-50" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> np.mean((output <span class="op">-</span> y_batch) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb45-51"><a href="#cb45-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="va">self</span>.model_type <span class="op">==</span> <span class="st">&#39;log_reg&#39;</span>:</span>
<span id="cb45-52"><a href="#cb45-52" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> <span class="op">-</span>np.mean(y_batch <span class="op">*</span> np.log(np.clip(output, <span class="va">self</span>.eps, <span class="fl">1.0</span>)) <span class="op">+</span></span>
<span id="cb45-53"><a href="#cb45-53" aria-hidden="true" tabindex="-1"></a>                     (<span class="dv">1</span> <span class="op">-</span> y_batch) <span class="op">*</span> np.log(np.clip(<span class="dv">1</span> <span class="op">-</span> output, <span class="va">self</span>.eps, <span class="fl">1.0</span>)))</span>
<span id="cb45-54"><a href="#cb45-54" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">+=</span> reg_loss</span>
<span id="cb45-55"><a href="#cb45-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-56"><a href="#cb45-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> loss</span>
<span id="cb45-57"><a href="#cb45-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-58"><a href="#cb45-58" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> calc_loss_grad(<span class="va">self</span>, X_batch, y_batch):</span>
<span id="cb45-59"><a href="#cb45-59" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb45-60"><a href="#cb45-60" aria-hidden="true" tabindex="-1"></a><span class="co">        Считаем  градиент функции потерь по батчу (то что Вы вывели в задании 1)</span></span>
<span id="cb45-61"><a href="#cb45-61" aria-hidden="true" tabindex="-1"></a><span class="co">        X_batch - матрица объекты-признаки по батчу</span></span>
<span id="cb45-62"><a href="#cb45-62" aria-hidden="true" tabindex="-1"></a><span class="co">        y_batch - вектор ответов по батчу</span></span>
<span id="cb45-63"><a href="#cb45-63" aria-hidden="true" tabindex="-1"></a><span class="co">        Не забудте тип модели (линейная или логистическая регрессия)!</span></span>
<span id="cb45-64"><a href="#cb45-64" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb45-65"><a href="#cb45-65" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.calculate_model_output(X_batch)</span>
<span id="cb45-66"><a href="#cb45-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-67"><a href="#cb45-67" aria-hidden="true" tabindex="-1"></a>        reg_grad <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb45-68"><a href="#cb45-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.C <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb45-69"><a href="#cb45-69" aria-hidden="true" tabindex="-1"></a>            reg_grad <span class="op">=</span> np.hstack([[<span class="dv">0</span>], <span class="dv">2</span> <span class="op">*</span> <span class="fl">1.</span><span class="op">/</span><span class="va">self</span>.C <span class="op">*</span> <span class="va">self</span>.weights[<span class="dv">1</span>:]])</span>
<span id="cb45-70"><a href="#cb45-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-71"><a href="#cb45-71" aria-hidden="true" tabindex="-1"></a>        loss_grad <span class="op">=</span> X_batch.T <span class="op">@</span> (output <span class="op">-</span> y_batch)</span>
<span id="cb45-72"><a href="#cb45-72" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.model_type <span class="op">==</span> <span class="st">&#39;lin_reg&#39;</span>:</span>
<span id="cb45-73"><a href="#cb45-73" aria-hidden="true" tabindex="-1"></a>            loss_grad <span class="op">*=</span> <span class="dv">2</span></span>
<span id="cb45-74"><a href="#cb45-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-75"><a href="#cb45-75" aria-hidden="true" tabindex="-1"></a>        loss_grad <span class="op">+=</span> reg_grad</span>
<span id="cb45-76"><a href="#cb45-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-77"><a href="#cb45-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> loss_grad</span>
<span id="cb45-78"><a href="#cb45-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-79"><a href="#cb45-79" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update_weights(<span class="va">self</span>, new_grad):</span>
<span id="cb45-80"><a href="#cb45-80" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb45-81"><a href="#cb45-81" aria-hidden="true" tabindex="-1"></a><span class="co">        Обновляем вектор весов</span></span>
<span id="cb45-82"><a href="#cb45-82" aria-hidden="true" tabindex="-1"></a><span class="co">        new_grad - градиент по батчу</span></span>
<span id="cb45-83"><a href="#cb45-83" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb45-84"><a href="#cb45-84" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights <span class="op">-=</span> <span class="va">self</span>.alpha <span class="op">*</span> new_grad</span>
<span id="cb45-85"><a href="#cb45-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-86"><a href="#cb45-86" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> pad_fake_bias_feature(<span class="va">self</span>, X):</span>
<span id="cb45-87"><a href="#cb45-87" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.hstack([np.ones((X.shape[<span class="dv">0</span>], <span class="dv">1</span>)), X])</span>
<span id="cb45-88"><a href="#cb45-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-89"><a href="#cb45-89" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> calculate_model_output(<span class="va">self</span>, X):</span>
<span id="cb45-90"><a href="#cb45-90" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> X <span class="op">@</span> <span class="va">self</span>.weights</span>
<span id="cb45-91"><a href="#cb45-91" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.model_type <span class="op">==</span> <span class="st">&#39;log_reg&#39;</span>:</span>
<span id="cb45-92"><a href="#cb45-92" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> sigmoid(output)</span>
<span id="cb45-93"><a href="#cb45-93" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output</span>
<span id="cb45-94"><a href="#cb45-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-95"><a href="#cb45-95" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y):</span>
<span id="cb45-96"><a href="#cb45-96" aria-hidden="true" tabindex="-1"></a>        <span class="co">&#39;&#39;&#39;</span></span>
<span id="cb45-97"><a href="#cb45-97" aria-hidden="true" tabindex="-1"></a><span class="co">        Обучение модели</span></span>
<span id="cb45-98"><a href="#cb45-98" aria-hidden="true" tabindex="-1"></a><span class="co">        X - матрица объекты-признаки</span></span>
<span id="cb45-99"><a href="#cb45-99" aria-hidden="true" tabindex="-1"></a><span class="co">        y - вектор ответов</span></span>
<span id="cb45-100"><a href="#cb45-100" aria-hidden="true" tabindex="-1"></a><span class="co">        &#39;&#39;&#39;</span></span>
<span id="cb45-101"><a href="#cb45-101" aria-hidden="true" tabindex="-1"></a>        X_padded <span class="op">=</span> <span class="va">self</span>.pad_fake_bias_feature(X)</span>
<span id="cb45-102"><a href="#cb45-102" aria-hidden="true" tabindex="-1"></a>        n_samples <span class="op">=</span> X_padded.shape[<span class="dv">0</span>]</span>
<span id="cb45-103"><a href="#cb45-103" aria-hidden="true" tabindex="-1"></a>        n_features <span class="op">=</span> X_padded.shape[<span class="dv">1</span>]</span>
<span id="cb45-104"><a href="#cb45-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-105"><a href="#cb45-105" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Нужно инициализровать случайно веса</span></span>
<span id="cb45-106"><a href="#cb45-106" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights <span class="op">=</span> np.random.normal(<span class="dv">0</span>, math.sqrt(<span class="dv">2</span><span class="op">/</span>(n_features <span class="op">+</span> <span class="dv">1</span>)), (n_features))</span>
<span id="cb45-107"><a href="#cb45-107" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> n <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="va">self</span>.max_epoch):</span>
<span id="cb45-108"><a href="#cb45-108" aria-hidden="true" tabindex="-1"></a>            new_epoch_generator <span class="op">=</span> <span class="va">self</span>.batch_generator(X_padded, y, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb45-109"><a href="#cb45-109" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> batch_num, (X_batch, y_batch) <span class="kw">in</span> <span class="bu">enumerate</span>(new_epoch_generator):</span>
<span id="cb45-110"><a href="#cb45-110" aria-hidden="true" tabindex="-1"></a>                batch_grad <span class="op">=</span> <span class="va">self</span>.calc_loss_grad(X_batch, y_batch)</span>
<span id="cb45-111"><a href="#cb45-111" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.update_weights(batch_grad)</span>
<span id="cb45-112"><a href="#cb45-112" aria-hidden="true" tabindex="-1"></a>                batch_loss <span class="op">=</span> <span class="va">self</span>.calc_loss(X_batch, y_batch)</span>
<span id="cb45-113"><a href="#cb45-113" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.errors_log[<span class="st">&#39;iter&#39;</span>].append(batch_num)</span>
<span id="cb45-114"><a href="#cb45-114" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.errors_log[<span class="st">&#39;loss&#39;</span>].append(batch_loss)</span>
<span id="cb45-115"><a href="#cb45-115" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Подумайте в каком месте стоит посчитать ошибку для отладки модели</span></span>
<span id="cb45-116"><a href="#cb45-116" aria-hidden="true" tabindex="-1"></a>                <span class="co"># До градиентного шага или после</span></span>
<span id="cb45-117"><a href="#cb45-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-118"><a href="#cb45-118" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb45-119"><a href="#cb45-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-120"><a href="#cb45-120" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb45-121"><a href="#cb45-121" aria-hidden="true" tabindex="-1"></a>        <span class="co">&#39;&#39;&#39;</span></span>
<span id="cb45-122"><a href="#cb45-122" aria-hidden="true" tabindex="-1"></a><span class="co">        Предсказание класса</span></span>
<span id="cb45-123"><a href="#cb45-123" aria-hidden="true" tabindex="-1"></a><span class="co">        X - матрица объекты-признаки</span></span>
<span id="cb45-124"><a href="#cb45-124" aria-hidden="true" tabindex="-1"></a><span class="co">        Не забудте тип модели (линейная или логистическая регрессия)!</span></span>
<span id="cb45-125"><a href="#cb45-125" aria-hidden="true" tabindex="-1"></a><span class="co">        &#39;&#39;&#39;</span></span>
<span id="cb45-126"><a href="#cb45-126" aria-hidden="true" tabindex="-1"></a>        X_padded <span class="op">=</span> <span class="va">self</span>.pad_fake_bias_feature(X)</span>
<span id="cb45-127"><a href="#cb45-127" aria-hidden="true" tabindex="-1"></a>        y_hat <span class="op">=</span> <span class="va">self</span>.calculate_model_output(X_padded)</span>
<span id="cb45-128"><a href="#cb45-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-129"><a href="#cb45-129" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> y_hat</span></code></pre></div>
</div>
<div class="cell markdown" id="6vgJ9C7ASxmt">
<p>Запустите обе регрессии на синтетических данных.</p>
<p>Выведите полученные веса и нарисуйте разделяющую границу между
классами (используйте только первых два веса для первых двух признаков
X[:,0], X[:,1] для отображения в 2d пространство ).</p>
</div>
<div class="cell code" id="J9x-34_hSxmt">
<div class="sourceCode" id="cb46"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_decision_boundary(clf):</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    b0, w1, w2 <span class="op">=</span> clf.weights</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.arange(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="fl">0.1</span>)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y = np.array([w1 * x_el + b0 for x_el in x])</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.plot(x, y, label=&#39;1&#39;)</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y = np.array([w1/w2 * x_el + b0/w2 for x_el in x])</span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.plot(x, y, label=&#39;2&#39;)</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> np.array([<span class="op">-</span>w1<span class="op">/</span>w2 <span class="op">*</span> x_el <span class="op">-</span> b0<span class="op">/</span>w2 <span class="cf">for</span> x_el <span class="kw">in</span> x])</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>    plt.plot(x, y, label<span class="op">=</span><span class="st">&#39;3&#39;</span>)</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:463}"
id="qsotuNYtSxmt" data-outputId="7e5a596c-f6e9-4fd1-f3d0-fded61fde6ff">
<div class="sourceCode" id="cb47"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>C1 <span class="op">=</span> np.array([[<span class="fl">0.</span>, <span class="op">-</span><span class="fl">0.8</span>], [<span class="fl">1.5</span>, <span class="fl">0.8</span>]])</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>C2 <span class="op">=</span> np.array([[<span class="fl">1.</span>, <span class="op">-</span><span class="fl">0.7</span>], [<span class="fl">2.</span>, <span class="fl">0.7</span>]])</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>gauss1 <span class="op">=</span> np.dot(np.random.randn(<span class="dv">200</span>, <span class="dv">2</span>) <span class="op">+</span> np.array([<span class="dv">5</span>, <span class="dv">3</span>]), C1)</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>gauss2 <span class="op">=</span> np.dot(np.random.randn(<span class="dv">200</span>, <span class="dv">2</span>) <span class="op">+</span> np.array([<span class="fl">1.5</span>, <span class="dv">0</span>]), C2)</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.vstack([gauss1, gauss2])</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.r_[np.ones(<span class="dv">200</span>), np.zeros(<span class="dv">200</span>)]</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>X_norm <span class="op">=</span> (X <span class="op">-</span> X.mean(axis<span class="op">=</span><span class="dv">0</span>)) <span class="op">/</span> X.std(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>cls <span class="op">=</span> MySGDClassifier(batch_generator, C<span class="op">=</span><span class="dv">1</span>, alpha<span class="op">=</span><span class="fl">1e-3</span>, max_epoch<span class="op">=</span><span class="dv">50</span>, model_type<span class="op">=</span><span class="st">&#39;log_reg&#39;</span>)</span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a>cls.fit(X_norm, y)</span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>plot_decision_boundary(cls)</span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_norm[:,<span class="dv">0</span>], X_norm[:,<span class="dv">1</span>], c<span class="op">=</span>y)</span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;acc = &quot;</span>, accuracy_score(y, cls.predict(X_norm) <span class="op">&gt;</span> <span class="fl">0.5</span>))</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_660fc6be0f2444d2af7376729dacc244/0a4749977a37406b55f9bf086b8b3392c6e0e2e0.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>acc =  0.8725
</code></pre>
</div>
</div>
<div class="cell markdown" id="fq5xQTb3Sxmu">
<p>Далее будем анализировать Ваш алгоритм. Для этих заданий используйте
датасет ниже.</p>
</div>
<div class="cell code" id="Ub94A6UmSxmu">
<div class="sourceCode" id="cb49"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_classification(n_samples<span class="op">=</span><span class="dv">100000</span>, n_features<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>                           n_informative<span class="op">=</span><span class="dv">4</span>, n_redundant<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>                           random_state<span class="op">=</span><span class="dv">123</span>, class_sep<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>                           n_clusters_per_class<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell markdown" id="eCrvNjjvSxmu">
<p>Покажите сходимости обеих регрессией на этом датасете: изобразите
график функции потерь, усредненной по <span
class="math inline"><em>N</em></span> шагам градиентого спуска, для
разных <code>alpha</code> (размеров шага). Разные <code>alpha</code>
расположите на одном графике.</p>
<p><span class="math inline"><em>N</em></span> можно брать 10, 50, 100 и
т.д.</p>
</div>
<div class="cell code" id="4nlB66Ob1aC1">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span></code></pre></div>
</div>
<div class="cell code" id="cT8meCZVSxmu">
<div class="sourceCode" id="cb51"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># X_norm = (X - X.mean(axis=0)) / X.std(axis=0)</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>X_norm <span class="op">=</span> X</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:573}"
id="FRBOqavh3MMC" data-outputId="99542c2a-4bc3-411e-d2ba-474c6c52f73c">
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> {}</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> alpha <span class="kw">in</span> [<span class="fl">1e-4</span>, <span class="fl">1e-3</span>, <span class="fl">1e-2</span>, <span class="fl">1e-1</span>, <span class="dv">1</span>]:</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>    my_cls <span class="op">=</span> MySGDClassifier(create_batch_generator_wrapper(batch_size<span class="op">=</span><span class="dv">400</span>), C<span class="op">=</span><span class="fl">0.0</span>, alpha<span class="op">=</span>alpha, max_epoch<span class="op">=</span><span class="dv">100</span>, model_type<span class="op">=</span><span class="st">&#39;log_reg&#39;</span>)</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>    my_cls.fit(X_norm, y)</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>    history[alpha] <span class="op">=</span> np.mean(np.array(my_cls.errors_log[<span class="st">&#39;loss&#39;</span>]).reshape(<span class="op">-</span><span class="dv">1</span>, N), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;lr </span><span class="sc">%f</span><span class="st">, acc </span><span class="sc">%f</span><span class="st">&quot;</span> <span class="op">%</span> (alpha, accuracy_score(y, my_cls.predict(X_norm) <span class="op">&gt;</span> <span class="fl">0.5</span>)))</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># break</span></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> alpha, hist <span class="kw">in</span> history.items():</span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a>    plt.plot(hist, label<span class="op">=</span><span class="bu">str</span>(alpha))</span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>lr 0.000100, acc 0.923360
lr 0.001000, acc 0.977610
lr 0.010000, acc 0.985190
lr 0.100000, acc 0.980000
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>&lt;ipython-input-97-3c6f944271cc&gt;:9: RuntimeWarning: overflow encountered in exp
  sigm_value_x = 1 / (1 + np.exp(-x))
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>lr 1.000000, acc 0.977710
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_660fc6be0f2444d2af7376729dacc244/da059e910ea58cd0d885cf7ef479fb7d768d0743.png" /></p>
</div>
</div>
<div class="cell markdown" id="0-YWhUEBSxmu">
<p>Что Вы можете сказать про сходимость метода при различных
<code>alpha</code>? Какое значение стоит выбирать для лучшей
сходимости?</p>
<p>Изобразите график среднего значения весов для обеих регрессий в
зависимости от коеф. регуляризации С из
<code>np.logspace(3, -3, 10)</code></p>
</div>
<div class="cell markdown" id="Nb5f_PN8S2dR">
<p>Можно сказать, что при слишком маленьком значении <code>alpha</code>
алгоритм просто не сможет сойтись</p>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="4OiNGnHESxmu" data-outputId="e69de703-881a-411d-80b9-239b203928c7">
<div class="sourceCode" id="cb56"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> {}</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a><span class="co"># with np.lospace(3, -3, 10) plot does not informative as it is not calibrated</span></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> C <span class="kw">in</span> np.logspace(<span class="dv">2</span>, <span class="op">-</span><span class="dv">2</span>, <span class="dv">10</span>):</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>    my_cls <span class="op">=</span> MySGDClassifier(create_batch_generator_wrapper(batch_size<span class="op">=</span><span class="dv">400</span>), C<span class="op">=</span>C, alpha<span class="op">=</span><span class="fl">1e-2</span>, max_epoch<span class="op">=</span><span class="dv">10</span>, model_type<span class="op">=</span><span class="st">&#39;log_reg&#39;</span>)</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>    my_cls.fit(X_norm, y)</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>    history[C] <span class="op">=</span> np.mean(my_cls.weights)</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;C </span><span class="sc">%f</span><span class="st">, acc </span><span class="sc">%f</span><span class="st">&quot;</span> <span class="op">%</span> (C, accuracy_score(y, my_cls.predict(X_norm) <span class="op">&gt;</span> <span class="fl">0.5</span>)))</span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;C&quot;</span>)</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;avg weights&quot;</span>)</span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a>plt.plot(history.keys(), history.values())</span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a>plt.plot(np.logspace(<span class="dv">2</span>, <span class="op">-</span><span class="dv">2</span>, <span class="dv">10</span>))</span>
<span id="cb56-19"><a href="#cb56-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>C 100.000000, acc 0.974110
C 35.938137, acc 0.972970
C 12.915497, acc 0.970150
C 4.641589, acc 0.967790
C 1.668101, acc 0.972210
C 0.599484, acc 0.976060
C 0.215443, acc 0.981180
C 0.077426, acc 0.979370
C 0.027826, acc 0.965310
C 0.010000, acc 0.066680
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_660fc6be0f2444d2af7376729dacc244/a7895eec0218cf24911170d5f37c398e032e13bb.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_660fc6be0f2444d2af7376729dacc244/7285765c93f61e26f6f83a4757e525514c0b9450.png" /></p>
</div>
</div>
<div class="cell markdown" id="VG6e66O9Sxmv">
<p>Довольны ли Вы, насколько сильно уменьшились Ваши веса?</p>
</div>
<div class="cell markdown" id="WnYT5nh7SplM">
<p>Достаточно</p>
</div>
</body>
</html>
